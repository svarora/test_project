{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8faa2d0c-5adf-49eb-8f88-15631af416dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Set tracking URI (for example, a remote server or specific directory)\n",
    "mlflow.set_tracking_uri('http://localhost:5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "496f2101-27f3-4e3f-bb8e-29b32a1106a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 22:12:46 INFO mlflow.tracking.fluent: Experiment with name 'house_price_prediction_experiment_With_regularization' does not exist. Creating a new experiment.\n",
      "2025/01/22 22:12:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged linear_regression to MLflow with MSE: 99442853452.60753 and R2 Score: 0.33522004975064035\n",
      "🏃 View run default at: http://localhost:5000/#/experiments/578991007214028464/runs/73dc3cd4b9464d1785e79d55000d14e6\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/578991007214028464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 22:12:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged ridge to MLflow with MSE: 99443029522.1547 and R2 Score: 0.3352188727177945\n",
      "🏃 View run ridge_default at: http://localhost:5000/#/experiments/578991007214028464/runs/70fae0ab0510425a8efc07b85c8e68b9\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/578991007214028464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 22:12:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged lasso to MLflow with MSE: 99442859113.23093 and R2 Score: 0.3352200119091182\n",
      "🏃 View run lasso_default at: http://localhost:5000/#/experiments/578991007214028464/runs/28fa2f9793394e9480beca8ff5a1ca6c\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/578991007214028464\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Set the MLflow experiment name\n",
    "mlflow.set_experiment('house_price_prediction_experiment_With_regularization')\n",
    "\n",
    "def train_and_log_experiment(model_name, params, run_name_param):\n",
    "    try:\n",
    "        # Load dataset\n",
    "        df = pd.read_csv('D:/BITS-wiLP/Semester-3/MLOPs/Assignment/ML Model Deployment/ML Model Deployment/data/house_data.csv')\n",
    "        X = df[['bedrooms', 'bathrooms', 'floors', 'yr_built']]\n",
    "        y = df['price']\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    # Initialize model based on model_name\n",
    "    if model_name == 'linear_regression':\n",
    "        model = LinearRegression(**params)\n",
    "    elif model_name == 'ridge':\n",
    "        model = Ridge(**params)\n",
    "    elif model_name == 'lasso':\n",
    "        model = Lasso(**params)\n",
    "    else:\n",
    "        print(f\"Unsupported model type: {model_name}\")\n",
    "        return\n",
    "    \n",
    "    # Start MLflow tracking\n",
    "    with mlflow.start_run(run_name=run_name_param):\n",
    "        # Log model parameters\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions and evaluation\n",
    "        predictions = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"mean_squared_error\", mse)\n",
    "        mlflow.log_metric(\"r2_score\", r2)\n",
    "        \n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "        print(f\"Logged {model_name} to MLflow with MSE: {mse} and R2 Score: {r2}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    experiments = [\n",
    "        {\"model_name\": \"linear_regression\", \"params\": {}, \"run_name_param\": \"default\"},\n",
    "        {\"model_name\": \"ridge\", \"params\": {\"alpha\": 1.0}, \"run_name_param\": \"ridge_default\"},\n",
    "        {\"model_name\": \"lasso\", \"params\": {\"alpha\": 0.1}, \"run_name_param\": \"lasso_default\"},\n",
    "    ]\n",
    "    for exp in experiments:\n",
    "        train_and_log_experiment(**exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2199977-0a25-4e7c-adbf-2ef1a65e84d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 22:18:48 INFO mlflow.tracking.fluent: Experiment with name 'Deep_learning_house_price_prediction_experiment_With_regularization' does not exist. Creating a new experiment.\n",
      "C:\\Users\\prash\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - loss: 386450751488.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 132852514816.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - loss: 119636148224.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 128226762752.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 128538329088.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 137015238656.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 139407081472.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 122273546240.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 130202025984.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 129250689024.0000\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 22:18:53 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/01/22 22:18:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "C:\\Users\\prash\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model 'nn_experiment_1' with MSE: 148888409675.7795 and R2 score: 0.004674281353542198\n",
      "🏃 View run nn_experiment_1 at: http://localhost:5000/#/experiments/210510871788310002/runs/eaf2f3f9cec64f6a887f4a6fcf6c2884\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/210510871788310002\n",
      "Epoch 1/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - loss: 385505787904.0000\n",
      "Epoch 2/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 155707621376.0000\n",
      "Epoch 3/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 135657684992.0000\n",
      "Epoch 4/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 122345529344.0000\n",
      "Epoch 5/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 129965670400.0000\n",
      "Epoch 6/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 127777415168.0000\n",
      "Epoch 7/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 131034152960.0000\n",
      "Epoch 8/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 123771158528.0000\n",
      "Epoch 9/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 121403580416.0000\n",
      "Epoch 10/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 125204226048.0000\n",
      "Epoch 11/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 124013133824.0000\n",
      "Epoch 12/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 128773005312.0000\n",
      "Epoch 13/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 129166778368.0000\n",
      "Epoch 14/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 131430916096.0000\n",
      "Epoch 15/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 138273914880.0000\n",
      "Epoch 16/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 136250818560.0000\n",
      "Epoch 17/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - loss: 131990495232.0000\n",
      "Epoch 18/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 133134237696.0000\n",
      "Epoch 19/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 133423316992.0000\n",
      "Epoch 20/20\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 120873500672.0000\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 22:19:04 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/01/22 22:19:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "C:\\Users\\prash\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model 'nn_experiment_2' with MSE: 148294338773.77353 and R2 score: 0.00864567206658473\n",
      "🏃 View run nn_experiment_2 at: http://localhost:5000/#/experiments/210510871788310002/runs/b20f7690568a4e05865a1b5a8781cc10\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/210510871788310002\n",
      "Epoch 1/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - loss: 408572133376.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 415017795584.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 407052091392.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 410328760320.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 409691062272.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 425045032960.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 416148815872.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 419081486336.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 422324633600.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 408410816512.0000\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 22:19:15 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/01/22 22:19:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "C:\\Users\\prash\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model 'nn_experiment_3' with MSE: 449636211908.40454 and R2 score: -2.0058383101932384\n",
      "🏃 View run nn_experiment_3 at: http://localhost:5000/#/experiments/210510871788310002/runs/bac77e58562e4140bab1b7de75c2a029\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/210510871788310002\n",
      "Epoch 1/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - loss: 241675452416.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - loss: 128112476160.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - loss: 136451801088.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - loss: 124564529152.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - loss: 134424780800.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - loss: 125189029888.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - loss: 122185957376.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - loss: 120873615360.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - loss: 133235916800.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - loss: 118770106368.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - loss: 138495213568.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - loss: 123850612736.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - loss: 132067221504.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - loss: 123065712640.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - loss: 134885138432.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - loss: 118819176448.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - loss: 120281538560.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - loss: 134951469056.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - loss: 120381505536.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - loss: 119372111872.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - loss: 122678042624.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - loss: 134598131712.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - loss: 116062928896.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - loss: 112301907968.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - loss: 120157790208.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - loss: 102222692352.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - loss: 109397041152.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - loss: 113141497856.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - loss: 112433733632.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - loss: 100725014528.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - loss: 100060127232.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - loss: 100337270784.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - loss: 98888269824.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - loss: 97975377920.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - loss: 96040583168.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - loss: 100501979136.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - loss: 97969733632.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - loss: 86462750720.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - loss: 91836948480.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - loss: 100010967040.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - loss: 86411345920.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - loss: 91801157632.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - loss: 97600995328.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - loss: 88504573952.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - loss: 91914379264.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - loss: 86676987904.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - loss: 90911653888.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - loss: 86032080896.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - loss: 86194855936.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m1014/1014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - loss: 92040757248.0000\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 22:20:00 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/01/22 22:20:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model 'nn_experiment_4' with MSE: 102922635569.57983 and R2 score: 0.3119575497088256\n",
      "🏃 View run nn_experiment_4 at: http://localhost:5000/#/experiments/210510871788310002/runs/626d6dc6888b4cc799f85dbc1e0a7b96\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/210510871788310002\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the MLflow experiment name\n",
    "mlflow.set_experiment('Deep_learning_house_price_prediction_experiment_With_regularization')\n",
    "# Load the dataset\n",
    "df = pd.read_csv('D:/BITS-wiLP/Semester-3/MLOPs/Assignment/ML Model Deployment/ML Model Deployment/data/house_data.csv')\n",
    "#df = pd.read_csv('house_data.csv')\n",
    "X = df[['bedrooms', 'bathrooms', 'floors', 'yr_built']]\n",
    "y = df['price']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Function to build and train the model based on experiment parameters\n",
    "def train_and_log_experiment(experiment_config):\n",
    "    model_name = experiment_config[\"model_name\"]\n",
    "    epochs = experiment_config.get(\"epochs\", 10)\n",
    "    batch_size = experiment_config.get(\"batch_size\", 32)\n",
    "    activation_function = experiment_config.get(\"activation\", 'relu')\n",
    "    units = experiment_config.get(\"units\", [64, 32])\n",
    "    \n",
    "    # Build a neural network model with variable configuration\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units[0], input_dim=X_train.shape[1], activation=activation_function))\n",
    "    model.add(Dense(units[1], activation=activation_function))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "        # Predictions\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"mean_squared_error\", mse)\n",
    "        mlflow.log_metric(\"r2_score\", r2)\n",
    "        \n",
    "        # Log model and parameters\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"activation_function\", activation_function)\n",
    "        mlflow.log_param(\"units\", units)\n",
    "        \n",
    "        # Log the model\n",
    "        mlflow.keras.log_model(model, \"neural_network_model\")\n",
    "\n",
    "        print(f\"Logged model '{model_name}' with MSE: {mse} and R2 score: {r2}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # List of experiments with different configurations\n",
    "    experiments = [\n",
    "        {\"model_name\": \"nn_experiment_1\", \"epochs\": 10, \"batch_size\": 32, \"activation\": 'relu', \"units\": [64, 32]},\n",
    "        {\"model_name\": \"nn_experiment_2\", \"epochs\": 20, \"batch_size\": 64, \"activation\": 'relu', \"units\": [128, 64]},\n",
    "        {\"model_name\": \"nn_experiment_3\", \"epochs\": 10, \"batch_size\": 32, \"activation\": 'tanh', \"units\": [64, 32]},\n",
    "        {\"model_name\": \"nn_experiment_4\", \"epochs\": 50, \"batch_size\": 16, \"activation\": 'relu', \"units\": [256, 128]},\n",
    "    ]\n",
    "    \n",
    "    for exp in experiments:\n",
    "        train_and_log_experiment(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87064b50-c944-4e2c-b119-2ffb054d68fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
